{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39c76583",
   "metadata": {},
   "source": [
    "## circuit-level noise model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873c4689",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import stim\n",
    "print(stim.__version__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from ldpc import bp_decoder, bposd_decoder\n",
    "import time\n",
    "from src.utils import rank\n",
    "from src.codes_q import create_bivariate_bicycle_codes, create_circulant_matrix\n",
    "from src.build_circuit import build_circuit, dem_to_check_matrices\n",
    "from src import osd_window\n",
    "\n",
    "\"\"\"导入我们的解码器\"\"\"\n",
    "from gauss_decoder import gauss_decoder\n",
    "\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45556bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_time = []\n",
    "\n",
    "\n",
    "def sliding_window_decoder(\n",
    "    N,\n",
    "    p=0.003,\n",
    "    num_repeat=12,\n",
    "    num_shots=10000,\n",
    "    max_iter=200,\n",
    "    W=2,\n",
    "    F=1,\n",
    "    z_basis=True,\n",
    "    noisy_prior=None,\n",
    "    method=0,\n",
    "    plot=False,\n",
    "    # shorten=False,\n",
    "    decoder_type=\"BP\",\n",
    "):\n",
    "\n",
    "    if N == 72:\n",
    "        code, A_list, B_list = create_bivariate_bicycle_codes(\n",
    "            6, 6, [3], [1, 2], [1, 2], [3]\n",
    "        )  # 72\n",
    "    elif N == 90:\n",
    "        code, A_list, B_list = create_bivariate_bicycle_codes(\n",
    "            15, 3, [9], [1, 2], [2, 7], [0]\n",
    "        )  # 90\n",
    "    elif N == 108:\n",
    "        code, A_list, B_list = create_bivariate_bicycle_codes(\n",
    "            9, 6, [3], [1, 2], [1, 2], [3]\n",
    "        )  # 108\n",
    "    elif N == 144:\n",
    "        code, A_list, B_list = create_bivariate_bicycle_codes(\n",
    "            12, 6, [3], [1, 2], [1, 2], [3]\n",
    "        )  # 144\n",
    "    elif N == 288:\n",
    "        code, A_list, B_list = create_bivariate_bicycle_codes(\n",
    "            12, 12, [3], [2, 7], [1, 2], [3]\n",
    "        )  # 288\n",
    "    elif N == 360:\n",
    "        code, A_list, B_list = create_bivariate_bicycle_codes(\n",
    "            30, 6, [9], [1, 2], [25, 26], [3]\n",
    "        )  # 360\n",
    "    elif N == 756:\n",
    "        code, A_list, B_list = create_bivariate_bicycle_codes(\n",
    "            21, 18, [3], [10, 17], [3, 19], [5]\n",
    "        )  # 756\n",
    "    else:\n",
    "        print(\"unsupported N\")\n",
    "        return\n",
    "\n",
    "    circuit = build_circuit(code, A_list, B_list, p, num_repeat, z_basis=z_basis)\n",
    "    dem = circuit.detector_error_model()\n",
    "    chk, obs, priors, col_dict = dem_to_check_matrices(dem, return_col_dict=True)\n",
    "    num_row, num_col = chk.shape\n",
    "    n = code.N\n",
    "    n_half = n // 2\n",
    "\n",
    "    lower_bounds = []\n",
    "    upper_bounds = []\n",
    "    i = 0\n",
    "    while i < num_row:\n",
    "        lower_bounds.append(i)\n",
    "        upper_bounds.append(i + n_half)\n",
    "        if i + n > num_row:\n",
    "            break\n",
    "        lower_bounds.append(i)\n",
    "        upper_bounds.append(i + n)\n",
    "        i += n_half\n",
    "\n",
    "    region_dict = {}\n",
    "    for i, (l, u) in enumerate(zip(lower_bounds, upper_bounds)):\n",
    "        region_dict[(l, u)] = i\n",
    "\n",
    "    region_cols = [[] for _ in range(len(region_dict))]\n",
    "\n",
    "    for i in range(num_col):\n",
    "        nnz_col = np.nonzero(chk[:, i])[0]\n",
    "        l = nnz_col.min() // n_half * n_half\n",
    "        u = (nnz_col.max() // n_half + 1) * n_half\n",
    "        region_cols[region_dict[(l, u)]].append(i)\n",
    "\n",
    "    chk = np.concatenate([chk[:, col].toarray() for col in region_cols], axis=1)\n",
    "    obs = np.concatenate([obs[:, col].toarray() for col in region_cols], axis=1)\n",
    "    priors = np.concatenate([priors[col] for col in region_cols])\n",
    "\n",
    "    anchors = []\n",
    "    j = 0\n",
    "    for i in range(num_col):\n",
    "        nnz_col = np.nonzero(chk[:, i])[0]\n",
    "        if nnz_col.min() >= j:\n",
    "            anchors.append((j, i))\n",
    "            j += n_half\n",
    "    anchors.append((num_row, num_col))\n",
    "\n",
    "    if noisy_prior is None and method != 0:\n",
    "        b = anchors[W]\n",
    "        c = anchors[W - 1]\n",
    "        if method == 1:\n",
    "            c = (c[0], c[1] + n_half * 3) if z_basis else (c[0], c[1] + n)\n",
    "        #             c = (c[0], c[1]+n_half*3) # try also this for x basis, change the later one as well\n",
    "        noisy_prior = np.sum(\n",
    "            chk[c[0] : b[0], c[1] : b[1]] * priors[c[1] : b[1]], axis=1\n",
    "        )\n",
    "        print(\"prior for noisy syndrome\", noisy_prior[0])\n",
    "\n",
    "    if method != 0:\n",
    "        noisy_syndrome_priors = np.ones(n_half) * noisy_prior\n",
    "\n",
    "    num_win = math.ceil((len(anchors) - W + F - 1) / F)\n",
    "    chk_submats = []\n",
    "    prior_subvecs = []\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(num_win, 1)\n",
    "    top_left = 0\n",
    "    i = 0\n",
    "    for i in range(num_win):\n",
    "        a = anchors[top_left]\n",
    "        bottom_right = min(top_left + W, len(anchors) - 1)\n",
    "        b = anchors[bottom_right]\n",
    "\n",
    "        if i != num_win - 1 and method != 0:  # not the last round\n",
    "            c = anchors[top_left + W - 1]\n",
    "            if method == 1:\n",
    "                c = (c[0], c[1] + n_half * 3) if z_basis else (c[0], c[1] + n)\n",
    "            #                 c = (c[0], c[1]+n_half*3) # try also this for x basis, change the previous one as well\n",
    "            noisy_syndrome = np.zeros((n_half * W, n_half))\n",
    "            noisy_syndrome[-n_half:, :] = np.eye(n_half)  # * noisy_syndrome_prior\n",
    "            mat = chk[a[0] : b[0], a[1] : c[1]]\n",
    "            mat = np.hstack((mat, noisy_syndrome))\n",
    "            prior = priors[a[1] : c[1]]\n",
    "            prior = np.concatenate((prior, noisy_syndrome_priors))\n",
    "        else:  # method==0 or last round\n",
    "            mat = chk[a[0] : b[0], a[1] : b[1]]\n",
    "            prior = priors[a[1] : b[1]]\n",
    "        chk_submats.append(mat)\n",
    "        prior_subvecs.append(prior)\n",
    "        if plot:\n",
    "            ax[i].imshow(mat, cmap=\"gist_yarg\")\n",
    "        top_left += F\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    dem_sampler: stim.CompiledDemSampler = dem.compile_sampler()\n",
    "    det_data, obs_data, err_data = dem_sampler.sample(\n",
    "        shots=num_shots, return_errors=False, bit_packed=False\n",
    "    )\n",
    "    end_time = time.perf_counter()\n",
    "    print(\n",
    "        f\"Stim: noise sampling for {num_shots} shots, Elapsed time:\",\n",
    "        end_time - start_time,\n",
    "    )\n",
    "\n",
    "    total_e_hat = np.zeros((num_shots, num_col))\n",
    "    new_det_data = det_data.copy()\n",
    "    start_time = time.perf_counter()\n",
    "    top_left = 0\n",
    "    # 分窗口进行解码，提升效率\n",
    "    for i in range(num_win):\n",
    "        mat = chk_submats[i]\n",
    "        prior = prior_subvecs[i]\n",
    "        a = anchors[top_left]\n",
    "        bottom_right = min(top_left + W, len(anchors) - 1)\n",
    "        b = anchors[bottom_right]\n",
    "        c = anchors[top_left + F]  # commit region bottom right\n",
    "\n",
    "        \"\"\"choose decoder\"\"\"\n",
    "        if decoder_type == \"BP\":\n",
    "            bpd = bposd_decoder(\n",
    "                mat,  # the parity check matrix\n",
    "                error_rate=p,  # does not matter because channel_probs is assigned\n",
    "                channel_probs=prior,  # assign error_rate to each qubit. This will override \"error_rate\" input variable\n",
    "                max_iter=max_iter,  # the maximum number of iterations for BP)\n",
    "                bp_method=\"minimum_sum_log\",\n",
    "                ms_scaling_factor=1.0,  # min sum scaling factor. If set to zero the variable scaling factor method is used\n",
    "                osd_method=\"osd_cs\",\n",
    "                osd_order=-1,  # -1 for no osd (only BP)\n",
    "                input_vector_type=\"syndrome\",\n",
    "            )\n",
    "        if decoder_type == \"BP_OSD\":\n",
    "            bpd = bposd_decoder(\n",
    "                mat,  # the parity check matrix\n",
    "                error_rate=p,  # does not matter because channel_probs is assigned\n",
    "                channel_probs=prior,  # assign error_rate to each qubit. This will override \"error_rate\" input variable\n",
    "                max_iter=max_iter,  # the maximum number of iterations for BP)\n",
    "                bp_method=\"minimum_sum_log\",\n",
    "                ms_scaling_factor=1.0,  # min sum scaling factor. If set to zero the variable scaling factor method is used\n",
    "                osd_method=\"osd_0\",\n",
    "                osd_order=7,  # -1 for no osd (only BP)\n",
    "                input_vector_type=\"syndrome\",\n",
    "            )\n",
    "        if decoder_type == \"OSD_WIN\":  # run my version of OSD\n",
    "            # if after `pre_max_iter` BP iterations on the original PCM but not converged\n",
    "            # sort according to sum of the recent four posterior_llr from low to high\n",
    "            # pick the first `new_n` columns, default to 2*num_row\n",
    "            # run BP for `post_max_iter` iterations then OSD on the shortened window\n",
    "            # only support `min_sum_log` syndrome decoding\n",
    "            bpd = osd_window(\n",
    "                mat,\n",
    "                channel_probs=prior,\n",
    "                pre_max_iter=8,  # BP preprocessing on original PCM\n",
    "                post_max_iter=max_iter,  # BP on shortened PCM\n",
    "                ms_scaling_factor=1.0,\n",
    "                new_n=None,  # if set to None, 2*num_row columns will be kept\n",
    "                osd_method=\"osd_cs\",\n",
    "                osd_order=10,\n",
    "            )\n",
    "        if decoder_type == \"OUR\":\n",
    "            mat = mat.astype(int)\n",
    "            bpd = gauss_decoder(mat, error_rate=p)\n",
    "            print(f\"mat = {mat}, mat shape = {mat.shape}\")\n",
    "            bpd.pre_decode()\n",
    "\n",
    "        # 判断当前窗口是否解码成功。每个窗口内解码num_shots次\n",
    "        num_flag_err = 0\n",
    "        detector_win = new_det_data[:, a[0] : b[0]]\n",
    "        for j in range(num_shots):\n",
    "            decoding_start_time = time.perf_counter()\n",
    "            # print(f\"detector_win[j] = {detector_win[j]}\")\n",
    "            syndrome = [1 if item else 0 for item in detector_win[j]]\n",
    "            # print(f\"syndrome = {syndrome}\")\n",
    "            e_hat = bpd.decode(syndrome)  # detector_win[j] is syndrome, len == m\n",
    "\n",
    "            decoding_end_time = time.perf_counter()\n",
    "            # if shorten: print(f\"pm: {bpd.min_pm}\")\n",
    "            decoding_time.append(decoding_end_time - decoding_start_time)\n",
    "            is_flagged = ((mat @ e_hat + detector_win[j]) % 2).any()\n",
    "            num_flag_err += is_flagged\n",
    "            if i == num_win - 1:  # last window\n",
    "                total_e_hat[j][a[1] : b[1]] = e_hat\n",
    "            else:\n",
    "                total_e_hat[j][a[1] : c[1]] = e_hat[: c[1] - a[1]]\n",
    "\n",
    "        print(f\"Window {i}, flagged Errors: {num_flag_err}/{num_shots}\")\n",
    "\n",
    "        new_det_data = (det_data + total_e_hat @ chk.T) % 2\n",
    "        top_left += F\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    print(\"Elapsed time:\", end_time - start_time)\n",
    "\n",
    "    flagged_err = ((det_data + total_e_hat @ chk.T) % 2).any(axis=1)\n",
    "    num_flagged_err = flagged_err.astype(int).sum()\n",
    "    print(f\"Overall Flagged Errors: {num_flagged_err}/{num_shots}\")\n",
    "    logical_err = ((obs_data + total_e_hat @ obs.T) % 2).any(axis=1)\n",
    "    num_err = np.logical_or(flagged_err, logical_err).astype(int).sum()\n",
    "    print(f\"Logical Errors: {num_err}/{num_shots}\")\n",
    "    p_l = num_err / num_shots\n",
    "    p_l_per_round = 1 - (1 - p_l) ** (1 / num_repeat)\n",
    "    # may also use ** (1/(num_repeat-1))\n",
    "    # because the first round is for encoding, the next (num_repeat-1) rounds are syndrome measurements rounds\n",
    "    print(\"logical error per round:\", p_l_per_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713970e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our decoder\n",
    "sliding_window_decoder(\n",
    "    N=144,\n",
    "    p=0.004,\n",
    "    num_repeat=12,\n",
    "    W=3,\n",
    "    F=1,\n",
    "    num_shots=10000,\n",
    "    max_iter=200,\n",
    "    method=1,\n",
    "    z_basis=True,\n",
    "    decoder_type=\"OUR\",\n",
    ")\n",
    "\n",
    "plt.hist([x * 1000 for x in decoding_time])  # convert s to ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e78050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BP\n",
    "sliding_window_decoder(\n",
    "    N=144,\n",
    "    p=0.004,\n",
    "    num_repeat=12,\n",
    "    W=3,\n",
    "    F=1,\n",
    "    num_shots=10000,\n",
    "    max_iter=200,\n",
    "    method=1,\n",
    "    z_basis=True,\n",
    "    decoder_type=\"BP\",\n",
    ")\n",
    "\n",
    "plt.hist([x * 1000 for x in decoding_time])  # convert s to ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd219dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BP+OSD\n",
    "sliding_window_decoder(\n",
    "    N=144,\n",
    "    p=0.004,\n",
    "    num_repeat=12,\n",
    "    W=3,\n",
    "    F=1,\n",
    "    num_shots=10000,\n",
    "    max_iter=200,\n",
    "    method=1,\n",
    "    z_basis=True,\n",
    "    decoder_type=\"BP_OSD\",\n",
    ")\n",
    "\n",
    "plt.hist([x * 1000 for x in decoding_time])  # convert s to ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f590519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OSD with shortened window\n",
    "sliding_window_decoder(\n",
    "    N=144,\n",
    "    p=0.004,\n",
    "    num_repeat=12,\n",
    "    W=3,\n",
    "    F=1,\n",
    "    num_shots=10000,\n",
    "    max_iter=200,\n",
    "    method=1,\n",
    "    z_basis=True,\n",
    "    decoder_type=\"OSD_WIN\",\n",
    ")\n",
    "\n",
    "plt.hist([x * 1000 for x in decoding_time])  # convert s to ms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
