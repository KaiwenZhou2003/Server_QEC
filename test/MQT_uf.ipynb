{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hx shape: (144, 288)\n"
     ]
    }
   ],
   "source": [
    "from ldpc.codes import rep_code\n",
    "from bposd.hgp import hgp\n",
    "import numpy as np\n",
    "from ldpc import bposd_decoder\n",
    "from scipy.sparse import coo_matrix\n",
    "from mqt.qecc import *\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 参数设置\n",
    "\n",
    "# # [72,12,6]\n",
    "# ell = 6\n",
    "# m = 6\n",
    "\n",
    "# # [90,8,10]\n",
    "# ell = 15\n",
    "# m = 3\n",
    "\n",
    "# # [108,8,10]\n",
    "# ell = 9\n",
    "# m = 6\n",
    "\n",
    "# [144,12,12]\n",
    "# ell = 12\n",
    "# m = 6\n",
    "\n",
    "# # [288,12,18]\n",
    "ell = 12\n",
    "m = 12\n",
    "\n",
    "# # [784,24,24]\n",
    "# ell = 28\n",
    "# m = 14\n",
    "\n",
    "n = 2 * m * ell\n",
    "\n",
    "\n",
    "# 定义循环移位矩阵\n",
    "def cyclic_shift_matrix(size, shift):\n",
    "    I = np.eye(size, dtype=int)\n",
    "    return np.roll(I, shift, axis=1)\n",
    "\n",
    "\n",
    "# 生成多项式 A 和 B 的循环矩阵\n",
    "A1 = cyclic_shift_matrix(ell * m, 3)  # x^3\n",
    "A2 = cyclic_shift_matrix(ell * m, 1)  # y^1\n",
    "A3 = cyclic_shift_matrix(ell * m, 2)  # y^2\n",
    "A = (A1 + A2 + A3) % 2  # A = x^3 + y^1 + y^2\n",
    "\n",
    "B1 = cyclic_shift_matrix(ell * m, 3)  # y^3\n",
    "B2 = cyclic_shift_matrix(ell * m, 1)  # x^1\n",
    "B3 = cyclic_shift_matrix(ell * m, 2)  # x^2\n",
    "B = (B1 + B2 + B3) % 2  # B = y^3 + x^1 + x^2\n",
    "\n",
    "# 生成校验矩阵 H\n",
    "Hx = np.hstack((A, B))\n",
    "Hz = np.hstack((B.T, A.T))\n",
    "\n",
    "# 打印校验矩阵 Hx 和 Hz\n",
    "# print(\"Hx (X-check matrix):\")\n",
    "# print(Hx)\n",
    "# print(\"\\nHz (Z-check matrix):\")\n",
    "# print(Hz)\n",
    "# print(\"Hx shape:\", Hx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AC Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Belief Propagation (BP) Implementation\n",
    "def belief_propagation(H, sigma, max_iterations=10):\n",
    "    \"\"\"\n",
    "    Belief Propagation to estimate posterior probabilities.\n",
    "    H: Parity-check matrix\n",
    "    sigma: Syndrome\n",
    "    max_iterations: Maximum number of BP iterations\n",
    "    \"\"\"\n",
    "    m, n = H.shape\n",
    "    messages = np.zeros((m, n))  # Messages passed between variable and check nodes\n",
    "    posteriors = np.full(n, 0.5)  # Initialize posterior probabilities\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        # Variable to Check node updates\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                if H[i, j] == 1:\n",
    "                    product = np.prod(\n",
    "                        [\n",
    "                            1 - 2 * messages[i, k]\n",
    "                            for k in range(n)\n",
    "                            if H[i, k] == 1 and k != j\n",
    "                        ]\n",
    "                    )\n",
    "                    messages[i, j] = (1 - sigma[i]) * 0.5 * (1 + product) + sigma[\n",
    "                        i\n",
    "                    ] * 0.5 * (1 - product)\n",
    "\n",
    "        # Check to Variable node updates\n",
    "        for j in range(n):\n",
    "            product = 1\n",
    "            for i in range(m):\n",
    "                if H[i, j] == 1:\n",
    "                    product *= 1 - 2 * messages[i, j]\n",
    "            posteriors[j] = 0.5 * (1 + product)\n",
    "\n",
    "    return posteriors\n",
    "\n",
    "\n",
    "# Stage 2: Cluster Formation\n",
    "def cluster_formation(H, posteriors, K):\n",
    "    \"\"\"\n",
    "    Cluster Formation based on posteriors.\n",
    "    H: Parity-check matrix\n",
    "    posteriors: Posterior probabilities from BP\n",
    "    K: Number of columns to select for clusters\n",
    "    \"\"\"\n",
    "    # Sort columns based on posterior probabilities\n",
    "    column_order = np.argsort(-posteriors)  # Descending order\n",
    "    selected_columns = column_order[:K]\n",
    "\n",
    "    # Form clusters using Gaussian elimination\n",
    "    clusters = []\n",
    "    for col in selected_columns:\n",
    "        # Perform pivot operation and form a new cluster\n",
    "        cluster = [col]\n",
    "        for i in range(H.shape[0]):\n",
    "            if H[i, col] == 1:\n",
    "                cluster.extend(np.where(H[i] == 1)[0])\n",
    "        clusters.append(set(cluster))\n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "# Stage 3: Decode Each Cluster\n",
    "def decode_clusters(H, sigma, clusters):\n",
    "    \"\"\"\n",
    "    Decode errors within each cluster independently.\n",
    "    H: Parity-check matrix\n",
    "    sigma: Syndrome\n",
    "    clusters: List of clusters\n",
    "    \"\"\"\n",
    "    decoded_errors = np.zeros(H.shape[1], dtype=int)\n",
    "\n",
    "    for cluster in clusters:\n",
    "        sub_H = H[:, list(cluster)]\n",
    "        sub_sigma = sigma\n",
    "        try:\n",
    "            # Solve for errors in the cluster\n",
    "            error = np.linalg.solve(sub_H, sub_sigma)\n",
    "            for idx, col in enumerate(cluster):\n",
    "                decoded_errors[col] = error[idx]\n",
    "        except np.linalg.LinAlgError:\n",
    "            # If no solution, continue to the next cluster\n",
    "            pass\n",
    "\n",
    "    return decoded_errors\n",
    "\n",
    "\n",
    "# AC Main Function\n",
    "def ambiguity_clustering(H, sigma, max_iterations=10, K=10):\n",
    "    \"\"\"\n",
    "    Main function to perform AC decoding.\n",
    "    H: Parity-check matrix\n",
    "    sigma: Syndrome\n",
    "    max_iterations: Maximum number of BP iterations\n",
    "    K: Number of columns to select for clusters\n",
    "    \"\"\"\n",
    "    # Step 1: Belief Propagation\n",
    "    posteriors = belief_propagation(H, sigma, max_iterations)\n",
    "\n",
    "    # Step 2: Cluster Formation\n",
    "    clusters = cluster_formation(H, posteriors, K)\n",
    "\n",
    "    # Step 3: Decode Each Cluster\n",
    "    decoded_errors = decode_clusters(H, sigma, clusters)\n",
    "\n",
    "    return decoded_errors\n",
    "\n",
    "\n",
    "# Parameters for AC\n",
    "max_iterations = 9  # BP iterations\n",
    "K = int(0.1 * n) / 3  # The number of additional columns added to C in stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running trials: 100%|██████████| 100/100 [00:15<00:00,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good_trials_uf = 0\n",
      "bad_trials_uf = 100\n",
      "good_trials_bp = 0\n",
      "bad_trials_bp = 100\n",
      "good_trials_ac = 0\n",
      "bad_trials_ac = 100\n",
      "average time for UF = 5.652189254760742e-05\n",
      "average time for BP+OSD = 0.0551467752456665\n",
      "average time for AC = 0.09893503665924072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# UF decoder\n",
    "code = Code(Hx, Hz)\n",
    "uf_decoder = UFHeuristic()\n",
    "uf_decoder.set_code(code)\n",
    "\n",
    "# BP decoder\n",
    "Hx_sparse = coo_matrix(Hx)\n",
    "bpx_decoder = bposd_decoder(\n",
    "    Hx_sparse,\n",
    "    channel_probs=[None],\n",
    "    max_iter=10000,\n",
    "    bp_method=\"ms\",\n",
    "    ms_scaling_factor=0,\n",
    "    osd_method=\"osd_cs\",\n",
    "    osd_order=7,\n",
    ")\n",
    "\n",
    "trials = 100\n",
    "\n",
    "good_trials_bp = 0\n",
    "bad_trials_bp = 0\n",
    "good_trials_uf = 0\n",
    "bad_trials_uf = 0\n",
    "good_trials_ac = 0\n",
    "bad_trials_ac = 0\n",
    "\n",
    "time_uf = 0\n",
    "time_bp = 0\n",
    "time_ac = 0\n",
    "\n",
    "for i in tqdm(range(trials), desc=\"Running trials\"):\n",
    "    x_error = sample_iid_pauli_err(code.n, 0.05)\n",
    "    x_syndrome = code.get_x_syndrome(x_error)\n",
    "\n",
    "    \"\"\"\n",
    "    UF decoder\n",
    "    \"\"\"\n",
    "    uf_start_time = time.time()\n",
    "    uf_decoder.decode(x_syndrome)\n",
    "    uf_end_time = time.time()\n",
    "    result = uf_decoder.result\n",
    "    residual_err_uf = np.array(x_error) ^ np.array(result.estimate)\n",
    "    if code.is_x_stabilizer(residual_err_uf):\n",
    "        good_trials_uf += 1\n",
    "    else:\n",
    "        bad_trials_uf += 1\n",
    "    time_uf += uf_end_time - uf_start_time\n",
    "\n",
    "    \"\"\"\n",
    "    BP+OSD decoder\n",
    "    \"\"\"\n",
    "    x_syndrome_01 = np.array([int(x) for x in x_syndrome]).flatten()\n",
    "    bp_start_time = time.time()\n",
    "    bpx_decoder.decode(x_syndrome_01)\n",
    "    bp_end_time = time.time()\n",
    "    low_weight_error = bpx_decoder.osdw_decoding\n",
    "\n",
    "    # 计算残余错误\n",
    "    residual_err_bposd = (low_weight_error + x_error) % 2\n",
    "    if code.is_x_stabilizer(residual_err_bposd):  # 使用 code.is_x_stabilizer\n",
    "        good_trials_bp += 1\n",
    "    else:\n",
    "        bad_trials_bp += 1\n",
    "    time_bp += bp_end_time - bp_start_time\n",
    "\n",
    "    \"\"\"\n",
    "    AC decoder\n",
    "    \"\"\"\n",
    "    ac_start_time = time.time()\n",
    "    ac_result = ambiguity_clustering(Hx, x_syndrome, max_iterations, K)\n",
    "    ac_end_time = time.time()\n",
    "    residual_err_ac = (ac_result + x_error) % 2\n",
    "    if code.is_x_stabilizer(residual_err_ac):  # 使用 code.is_x_stabilizer\n",
    "        good_trials_ac += 1\n",
    "    else:\n",
    "        bad_trials_ac += 1\n",
    "    time_ac += ac_end_time - ac_start_time\n",
    "\n",
    "\n",
    "print(f\"good_trials_uf = {good_trials_uf}\")\n",
    "print(f\"bad_trials_uf = {bad_trials_uf}\")\n",
    "\n",
    "print(f\"good_trials_bp = {good_trials_bp}\")\n",
    "print(f\"bad_trials_bp = {bad_trials_bp}\")\n",
    "\n",
    "print(f\"good_trials_ac = {good_trials_ac}\")\n",
    "print(f\"bad_trials_ac = {bad_trials_ac}\")\n",
    "\n",
    "print(f\"average time for UF = {time_uf/trials}\")\n",
    "print(f\"average time for BP+OSD = {time_bp/trials}\")\n",
    "print(f\"average time for AC = {time_ac/trials}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
